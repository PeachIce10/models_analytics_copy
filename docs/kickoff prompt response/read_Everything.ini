1) One concise plan — stand up the analytics slice end-to-end

Layout & ownership (no code, just where logic goes)
	•	[ADD NEW FOLDER] analytics/jobs/<domain>/<model>/
	•	[ADD NEW FILE] cmd/main.go (orchestrate: load config → run pipeline → validate → upsert)
	•	[ADD NEW FILE] pipeline/<model>_pipeline.go (all math/joins live here)
	•	[ADD NEW FILE] pipeline/<model>_validate.go (required keys; dedupe on (id,model_version,as_of,store_id); numeric clamps)
	•	[ADD NEW FILE] Dockerfile (static build; non-root)
	•	[ADD NEW FILE] analytics/configs/<model>.yaml (inputs/output/window/version/job_slo)
	•	[ADD NEW FILE] analytics/schemas/models/<dataset>.schema.json (row contract)
	•	[ADD NEW FILE] deploy/k8s/jobs/<model>-cronjob.yaml (schedule; DSN env; deadlines/retries)
	•	If served:
	•	[ADD NEW FILE] signals/internal/services/<dataset>_service.go
	•	[ADD NEW FILE] signals/internal/graph/schema/<dataset>.graphqls
	•	[ADD NEW FILE] signals/internal/graph/schema/<dataset>.resolver.go
	•	[ADD NEW FILE] signals/proto/<dataset>.proto (optional gRPC)
	•	[EDIT EXISTING FILE] analytics/configs/signals.yaml → serving.<dataset> binding

System packages/services to provision
	•	[PROVISION SYSTEM] Container Registry, Kubernetes, Secrets Manager/K8s Secrets (CORE_PG_DSN, CORE_CH_DSN, SIGNALS_PG_DSN, SIGNALS_CH_DSN)
	•	[PROVISION SYSTEM] Postgres (serving/params) & ClickHouse (edges/scans)
	•	[PROVISION SYSTEM] Observability (Prometheus scrape + Grafana board)
	•	[PROVISION SYSTEM] ANN path (OpenSearch k-NN / Milvus / FAISS) for #2/#7/#12 as needed  ￼
	•	[PROVISION SYSTEM] Optimizer runtime (OR-Tools or CBC/GLPK) for #4/#9  ￼ ￼

CI/CD
	•	Build/test Go; docker build jobs + signals; push tags = model_version
	•	Deploy K8s manifests (CronJobs & signals Deployment/Service)
	•	CI checks: parse signals.yaml; verify each serving.<dataset> has matching store impl

SLO wiring & health
	•	[EDIT EXISTING FILE] analytics/signals/cmd/main.go → load signals.yaml, default request timeout, expose /healthz + /readyz
	•	[EDIT EXISTING FILE] analytics/signals/internal/store/factory.go → DSN pings + SELECT MAX(as_of), COUNT(*) vs freshness_hours/min_rows; fail fast
	•	[ADD NEW FILE] signals/internal/graph/schema/ops.graphqls + resolver → opsStatus{datasets{ name,store,ok,rows,maxAgeHours,lastAsOf,message}}
	•	Prom metrics to emit:
signals_dataset_ok{dataset}, signals_dataset_rows{dataset}, signals_dataset_max_age_hours{dataset}, job_rows_written{job}, job_runtime_seconds{job}

⸻

2) Dependency matrix — 15 models (dataset, IO, serve, cadence, params, capability/tooling)

#	Model	Dataset (table)	Inputs (PG/CH)	Serve online?	Cadence	Params table?	Capability / Tooling
1	CLV (BG/NBD + GG)	tiers_clv (PG)	orders (PG/CH), customers (PG)	No (admin optional)	Score daily; fit weekly	Y clv_params(r,alpha,a,b,p,q,gamma,as_of,store_id)	Regression / special funcs (Gonum ok). Spec & worked example.  ￼
2	Recommender (two-stage)	rank_weights (PG) + uses product_signals	product features (PG), events (CH)	Yes (PDP/PLP)	Weights weekly; features daily	Y rank_weights(feature,weight,as_of,store_id)	ANN retrieval + ranker. Stock & returns penalties.  ￼
3	Basket / Session re-rank	upsell_scores (PG)	carts (PG), product_graph (CH), products (PG)	Yes (Cart/Checkout)	Daily	N (rules in config)	Guardrailed attach with base-CVR penalty.  ￼
4	Promotion uplift	promotion_assignments (PG)	campaign features & budgets (PG), exposures (PG)	No (offline assign)	Weekly	Y uplift_params (if learned τ)	Uplift + knapsack / budget caps.  ￼
5	Personas (HDBSCAN)	personas (PG)	orders agg (PG/CH), events (CH)	No (UI optional)	Weekly/Monthly	N (cfg thresholds)	Clustering (HDBSCAN; K-Means fallback).  ￼
6	Affinities (brand/category)	customer_affinities (PG) or enrich product_signals	events (CH), customers (PG)	Optional	Daily	Y affinities_params(half_life,alpha,as_of)	Decayed counts + Dirichlet smoothing.  ￼
7	Product similarity / neighbors	similarity_artifacts (PG meta) + ANN index	orders→co-buy (CH), products (PG)	Yes (PDP/PLP)	Index weekly	Y similarity_artifacts(index_id,version,built_at,store_id)	Co-buy cosine / PPMI; ANN serving.  ￼
8	PLP/Search LTR	rank_weights (PG)	search logs (CH), product features (PG)	Yes (Search/PLP)	Weights weekly; features daily	Y rank_weights	Pairwise RankNet; freshness gates.  ￼
9	Markdown optimizer	markdown_plans (PG)	inventory (PG), pricing ladder (PG), forecast (PG/CH), products (PG)	No	Weekly	Y markdown_params (policy)	DP/MILP; risk-aware ladder.  ￼
10	Price elasticity (gated)	elasticity (PG)	price_history (PG), promos (PG), seasonality (PG), products (PG)	No	Weekly/Monthly	Y elasticity_params (optional)	Log-log; Lerner heuristic; guardrails.  ￼
11	Upsell propensity	upsell_scores (PG)	carts (PG), upsell_catalog (PG), orders/offers_log (PG), products (PG)	Yes (Checkout)	Daily	Y upsell_params(lambda,as_of,store_id) (if learned)	Logit/GBM + profit guardrail.  ￼
12	Cross-sell (complements)	cross_sell (PG)	product_graph embeddings/lift (CH), products (PG), carts (PG)	Yes (PDP/Cart)	Daily	Y cross_sell_params (optional)	Cosine+lift → prob; low-stock penalty; exclude substitutes.  ￼
13	Bundle optimizer	bundles (PG)	inventory (PG), products (PG), attach/cannibal priors (PG)	No	Weekly	Y bundle_params (caps/rules)	Knapsack/MILP; hero guardrails.  ￼
14	Churn propensity	churn_risk (PG)	customers (PG), orders (PG/CH), events (CH), support (PG)	No (admin optional)	Daily/Weekly	Y churn_params(coef_*,as_of)	Logit/GBM; treat if p*g>c.  ￼
15	Lifecycle timing (HSMM)	lifecycle_state (PG)	weekly events & orders (PG/CH)	No (admin optional)	Weekly	Y hsmm_params(duration_means,emissions,as_of)	HSMM (+ Hawkes optional); trigger rules.  ￼


⸻

3) Scaffold kit (copy/paste templates)

Config (per-model)
[ADD NEW FILE] analytics/configs/<model>.yaml

inputs:
  - { store: postgres|clickhouse, dsn_env: CORE_PG_DSN|CORE_CH_DSN, table: "<source_table>", where: "<optional_filter>" }
window: last_30d|last_90d|last_180d|last_365d|{start: "YYYY-MM-DD", end: "YYYY-MM-DD"}
output: { table: "<dataset>", store: postgres|clickhouse, dsn_env: SIGNALS_PG_DSN|SIGNALS_CH_DSN }
model_version: "<name>-<semver>"
job_slo: { max_runtime_sec: 900, max_retries: 2, backoff_sec: 30 }

Schema (dataset contract)
[ADD NEW FILE] analytics/schemas/models/<dataset>.schema.json

{
  "title": "<dataset> contract",
  "description": "All rows include keys for audit/versioning.",
  "required": ["id", "model_version", "as_of", "store_id"],
  "properties": {
    "id": { "type": "string" },
    "model_version": { "type": "string" },
    "as_of": { "type": "string", "format": "date-time" },
    "store_id": { "type": "string" }
    /* + add model-specific fields (e.g., clv_180_cents, tier, etc.) */
  }
}

CronJob (per job)
[ADD NEW FILE] deploy/k8s/jobs/<model>-cronjob.yaml

apiVersion: batch/v1
kind: CronJob
metadata: { name: "<model>-cron" }
spec:
  schedule: "0 3 * * *"   # daily at 03:00
  jobTemplate:
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: 1800
      template:
        spec:
          restartPolicy: Never
          containers:
            - name: <model>
              image: "<registry>/analytics-<model>:<model_version>"
              env:
                - { name: CORE_PG_DSN, valueFrom: { secretKeyRef: { name: core-dsns, key: CORE_PG_DSN } } }
                - { name: CORE_CH_DSN, valueFrom: { secretKeyRef: { name: core-dsns, key: CORE_CH_DSN } } }
                - { name: SIGNALS_PG_DSN, valueFrom: { secretKeyRef: { name: signals-dsns, key: SIGNALS_PG_DSN } } }
                - { name: SIGNALS_CH_DSN, valueFrom: { secretKeyRef: { name: signals-dsns, key: SIGNALS_CH_DSN } } }
              args: ["-config=/configs/<model>.yaml"]
          volumes: [ { name: configs, configMap: { name: analytics-configs } } ]

Signals (served datasets only)
	•	[ADD NEW FILE] signals/internal/services/<dataset>_service.go (thin reads + paging)
	•	[ADD NEW FILE] signals/internal/graph/schema/<dataset>.graphqls (types/queries)
	•	[ADD NEW FILE] signals/internal/graph/schema/<dataset>.resolver.go (calls service)
	•	[EDIT EXISTING FILE] analytics/configs/signals.yaml → add:

serving:
  <dataset>: { store: postgres|clickhouse, dsn_env: SIGNALS_PG_DSN|SIGNALS_CH_DSN }
slo:
  freshness_hours: { <dataset>: 36 }   # 72 if CH edges
  min_rows: { <dataset>: 1 }
  timeouts_ms: { store_ping: 1500, request_default: 2000 }
  paging: { max_limit: 200 }

Validation gates (put in *_validate.go for every model)
	•	Required fields present (incl. {id, model_version, as_of, store_id})
	•	Dedupe on (id, model_version, as_of, store_id)
	•	Numeric clamps: non-negative cents; probs in [0,1]; paging caps enforced in signals

⸻

4) Ops checklist
	•	Secrets: DSNs only in K8s Secrets; never in repo
	•	SLO checks: signals boot guards in store/factory.go + /readyz must fail on breach
	•	Metrics to emit:
	•	Serving: signals_dataset_ok{dataset}, signals_dataset_rows{dataset}, signals_dataset_max_age_hours{dataset}
	•	Jobs: job_rows_written{job}, job_runtime_seconds{job}
	•	Grafana board items: Datasets table (name/store/rows/lastAsOf/maxAgeHours/status), signals boot OK, per-job rows & runtime
	•	Runbooks:
	•	Boot fail → fix signals.yaml binding or DSNs → redeploy
	•	Stale data → re-run producing job → verify as_of & row count → opsStatus green
	•	Backfill → override window + bump model_version (dedupe keys prevent clobber)

⸻

5) Foundation jobs — fully specified (no code)

A) visitor_cohorts (PG) — daily
	•	Purpose: anon/session fallback cohorts for runtime decisions (#2/#3/#7/#8/#11/#12)  ￼
	•	Inputs:
	•	events (CH): session_id, store_id, page_type, product_id, action{view,click,atc,checkout}, ts, referrer, device, channel
	•	products (PG): product_id, brand_id, category_id
	•	Columns (PG table visitor_cohorts):
store_id, cohort_id, channel, device, referrer_domain, page_mix_jsonb, avg_depth, bounce_rate, atc_rate, purchase_rate, size, last_seen_at, as_of, model_version
	•	Cadence: daily (24h)
	•	Sample Cron env: needs CORE_CH_DSN (events), SIGNALS_PG_DSN (writes)
	•	Config analytics/configs/visitor_cohorts.yaml (example):
inputs: [{store: clickhouse, dsn_env: CORE_CH_DSN, table: events}] → output: {table: visitor_cohorts, store: postgres, dsn_env: SIGNALS_PG_DSN}

B) customer_signals (PG) — daily
	•	Purpose: per-user aggregates for personas, affinities, churn, lifecycle; light rules for #3/#11/#12  ￼ ￼
	•	Inputs:
	•	events (CH): view/click/open counts by brand/category
	•	orders (PG/CH): 30/90-day counts and GM
	•	campaigns (PG): opens/clicks (if available)
	•	products (PG): brand/category lookup
	•	Columns (PG table customer_signals):
store_id, user_id, views_by_brand jsonb, views_by_category jsonb, last_brand, last_category, last_channel, email_open_rate_90d, email_click_rate_90d, email_engaged bool, session_count_30d, atc_count_30d, purchase_count_90d, avg_view_to_atc_sec, avg_atc_to_buy_sec, as_of, model_version
	•	Cadence: daily
	•	Sample Cron env: CORE_PG_DSN, CORE_CH_DSN, SIGNALS_PG_DSN

⸻

6) Risk & decisions log (short)
	•	ANN choice (OpenSearch vs Milvus vs FAISS): pick per ops comfort & cost profile for #2/#7/#12; fallback to co-buy tables if deferred.  ￼
	•	Optimizer packaging for #4/#9 (OR-Tools vs CBC/GLPK vs Python sidecar): decide based on containerization & licensing; both paths are fine.  ￼
	•	Elasticity gating (#10): require ≥5 distinct price points/SKU or run price tests first; else keep OFF to avoid spurious ε.  ￼
	•	HSMM complexity (#15): if heavy for first cut, start with logistic gate on recency + visit-slope and migrate to HSMM later.  ￼
	•	Where to store #6 outputs: customer_affinities (new) vs enriching product_signals; choose one to keep serving simple.  ￼
	•	Returns handling in #2/#3/#12: ensure return-risk terms and low-stock penalties are available and fresh (pricing/stock feeds).  ￼ ￼

⸻

Notes mapping each model to your math blocks (for quick cross-check)
	•	#1 CLV: BG/NBD + Gamma–Gamma, worked example & formulae.  ￼
	•	#2 Two-stage Recommender: net margin per impression with stock/returns penalties.  ￼
	•	#3 Basket re-rank: guardrailed attach vs CVR drop (λ·Δp·baseGM).  ￼
	•	#4 Promotion uplift: τ(x) with budget/caps knapsack; persistent holdouts.  ￼
	•	#5 Personas: HDBSCAN core/mreach + silhouette; K-Means fallback.  ￼
	•	#6 Affinities: time-decay + Dirichlet smoothing.  ￼
	•	#7 Similarity: co-buy vectors + cosine/PPMI; ANN serving.  ￼
	•	#8 PLP LTR: pairwise RankNet; scoring illustration; freshness gates.  ￼
	•	#9 Markdown: stochastic ladder (DP/MILP) with salvage; risk-aware.  ￼
	•	#10 Elasticity: log-log; Lerner heuristic with guardrails.  ￼
	•	#11 Upsell: GBM/Logit with profit guardrail (λ·Δp·baseGM).  ￼
	•	#12 Cross-sell: cosine/lift → prob; low-stock penalty; exclude substitutes.  ￼
	•	#13 Bundles: attach−cannibal net value; knapsack under caps.  ￼
	•	#14 Churn: logit with treat-iff p*g > c.  ￼
	•	#15 Lifecycle (HSMM): duration PMFs + emissions; posterior trigger rule.  ￼

⸻

7) Touch points in your existing repo (explicit edits)
	•	[EDIT EXISTING FILE] analytics/common/config/load.go → strict loaders & env overrides; required-key validation
	•	[EDIT EXISTING FILE] analytics/common/datastore/{postgres.go,clickhouse.go} → SelectFreshness, SelectCount, UpsertRows(keys=[id,model_version,as_of,store_id])
	•	[EDIT EXISTING FILE] analytics/common/timewin/window.go → last_30d/90d/180d/365d + Custom
	•	[EDIT EXISTING FILE] analytics/signals/cmd/main.go & signals/internal/store/factory.go → boot checks + /healthz,/readyz + opsStatus
	•	[EDIT EXISTING FILE] signals/internal/validators/* → required IDs, paging clamp, numeric bounds

⸻

